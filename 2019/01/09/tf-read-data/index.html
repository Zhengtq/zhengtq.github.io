<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>&lt; Tensorflow &gt; Data flow in Tensorflow - Billy&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Billy&#039;s Blog"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Billy&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Using data queue to read data(abandoned, not support in future Tensorflow version)If you store you data in traditional hard disk, I suggest you read data through the data format of  tfrecord. However,"><meta property="og:type" content="article"><meta property="og:title" content="&lt; Tensorflow &gt; Data flow in Tensorflow"><meta property="og:url" content="https://zhengtq.github.io/2019/01/09/tf-read-data/"><meta property="og:site_name" content="Billy&#039;s Blog"><meta property="og:description" content="Using data queue to read data(abandoned, not support in future Tensorflow version)If you store you data in traditional hard disk, I suggest you read data through the data format of  tfrecord. However,"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhengtq.github.io/img/og_image.png"><meta property="article:published_time" content="2019-01-09T11:04:09.000Z"><meta property="article:modified_time" content="2021-03-12T06:16:24.603Z"><meta property="article:author" content="Billy"><meta property="article:tag" content="Tensorflow"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zhengtq.github.io/2019/01/09/tf-read-data/"},"headline":"< Tensorflow > Data flow in Tensorflow","image":["https://zhengtq.github.io/img/og_image.png"],"datePublished":"2019-01-09T11:04:09.000Z","dateModified":"2021-03-12T06:16:24.603Z","author":{"@type":"Person","name":"Billy"},"description":"Using data queue to read data(abandoned, not support in future Tensorflow version)If you store you data in traditional hard disk, I suggest you read data through the data format of  tfrecord. However,"}</script><link rel="canonical" href="https://zhengtq.github.io/2019/01/09/tf-read-data/"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Billy&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-01-09T11:04:09.000Z" title="1/9/2019, 7:04:09 PM">2019-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-12T06:16:24.603Z" title="3/12/2021, 2:16:24 PM">2021-03-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile">&lt; Tensorflow &gt; Data flow in Tensorflow</h1><div class="content"><h1 id="Using-data-queue-to-read-data-abandoned-not-support-in-future-Tensorflow-version"><a href="#Using-data-queue-to-read-data-abandoned-not-support-in-future-Tensorflow-version" class="headerlink" title="Using data queue to read data(abandoned, not support in future Tensorflow version)"></a>Using data queue to read data(abandoned, not support in future Tensorflow version)</h1><p>If you store you data in traditional hard disk, I suggest you read data through the data format of  tfrecord. However, if you store your data in solid state drives , I suggest that you read by FIFO Queue to directly read image by its root.<br>Firstly, you have to set up a FIFO Queue:<br><span id="more"></span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input_queue = data_flow_ops.FIFOQueue(capacity=<span class="number">3000000</span>,</span><br><span class="line">		                    dtypes=[tf.string, tf.int64],</span><br><span class="line">		                    shapes=[(<span class="number">1</span>,), (<span class="number">1</span>,)],</span><br><span class="line">		                    shared_name=<span class="literal">None</span>, name=<span class="literal">None</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>The queue above contain two values. The first is image root, and the second is image label.<br>To load image roots and labels to the FIFO Queue,  you have to use the a enqueue_op.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">enqueue_op &#x3D; input_queue.enqueue_many([image_paths_placeholder, labels_placeholder], name&#x3D;&#39;enqueue_op&#39;)</span><br></pre></td></tr></table></figure>
<p>Next, you should open up a session to feed your image roots and labels to respective placeholder.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess.run(enqueue_op, &#123;image_paths_placeholder: image_paths_array, labels_placeholder: labels_array&#125;)</span><br></pre></td></tr></table></figure>
<p>During training, you have to dequeue the FIFO Queue and use multi-thread to accelerate the process. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">images_and_labels_list = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(preprocess_threads):</span><br><span class="line">	filenames, label= input_queue.dequeue()</span><br><span class="line">	images = []</span><br><span class="line">               image_depths = []</span><br><span class="line">	<span class="keyword">for</span> filename, single_label <span class="keyword">in</span> <span class="built_in">zip</span>(tf.unstack(filenames), tf.unstack(label)):</span><br><span class="line">	    file_contents = tf.read_file(filename)</span><br><span class="line">   		    image = tf.image.decode_bmp(file_contents, channels=<span class="number">3</span>)</span><br><span class="line">   		    image = tf.reshape(image, original_img_shape)</span><br><span class="line">	    images.append(image)</span><br><span class="line">	images_and_labels_list.append([images, label])</span><br></pre></td></tr></table></figure>
<p>Finally, to create batches of examples, you should use “tf.train.batch_join” api.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">img_batch, img_depth_batch,label_batch &#x3D; tf.train.batch_join(</span><br><span class="line">	images_and_labels_list, batch_size&#x3D;batch_size, </span><br><span class="line">	shapes&#x3D;[[to_height, to_width, channels], ()], enqueue_many&#x3D;True,</span><br><span class="line">	capacity&#x3D;4 * preprocess_threads * 100,</span><br><span class="line">	allow_smaller_final_batch&#x3D;True)</span><br></pre></td></tr></table></figure>
<h1 id="Using-tf-data-API"><a href="#Using-tf-data-API" class="headerlink" title="Using tf.data API"></a>Using tf.data API</h1><p>Tensorflow officially promote using tf.data API for data processing. Using tf.data API is relatively easy to coding.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">_parse_data</span>(<span class="params">line</span>):</span></span><br><span class="line">       file_contents = tf.read_file(image_filepath)</span><br><span class="line">image = tf.image.decode_bmp(file_contents, channels=<span class="number">3</span>)</span><br><span class="line">       image = tf.reshape(image, original_img_shape)</span><br><span class="line">       <span class="keyword">return</span> image, single_label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   dataset = tf.data.TextLineDataset([file_root])</span><br><span class="line"></span><br><span class="line">   dataset = dataset.<span class="built_in">map</span>(map_func=_parse_data,  num_parallel_calls=<span class="number">4</span>)</span><br><span class="line">   dataset = dataset.shuffle(buffer_size=batch_size * <span class="number">3</span>)</span><br><span class="line">   dataset = dataset.batch(batch_size)</span><br><span class="line">   dataset = dataset.repeat(epoc)</span><br><span class="line">   dataset = dataset.prefetch(<span class="number">2000</span>)</span><br><span class="line">   data_iterator = dataset.make_one_shot_iterator()</span><br><span class="line"> </span><br><span class="line">   <span class="keyword">return</span> data_iterator</span><br></pre></td></tr></table></figure>
<p>To accelerate the reading process, <strong>do not forget to use dataset.prefetch and num_parallel_calls</strong>. </p>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Tensorflow/">Tensorflow</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/01/30/face-as/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">&lt; Antispoofing &gt; Does we should align in Face Antispoofing</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/01/05/tf-rnn-gru/"><span class="level-item">&lt; Tensorflow &gt; What is the implementation of GRU in tensorflow</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Billy"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Billy</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">45</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">10</p></a></div></div></nav></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-27T00:38:00.000Z">2021-01-27</time></p><p class="title"><a href="/2021/01/27/tf2-x-best-practice/">&lt; Tensorflow &gt;Tensorflow2.4 最佳实践</a></p><p class="categories"><a href="/categories/Tensorflow/">Tensorflow</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-28T05:54:05.000Z">2020-12-28</time></p><p class="title"><a href="/2020/12/28/ncnn-lesson-start/">&lt; NCNN-Lession-Start &gt;　Start</a></p><p class="categories"><a href="/categories/Deeplearning/">Deeplearning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-21T03:10:11.000Z">2020-12-21</time></p><p class="title"><a href="/2020/12/21/ncnn-lesson-10/">&lt; NCNN-Lession-10 &gt;　Forward Net</a></p><p class="categories"><a href="/categories/Deeplearning/">Deeplearning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-21T03:10:11.000Z">2020-12-21</time></p><p class="title"><a href="/2020/12/21/ncnn-lesson-9/">&lt; NCNN-Lession-9 &gt;　Load Image</a></p><p class="categories"><a href="/categories/Deeplearning/">Deeplearning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-18T02:19:11.000Z">2020-12-18</time></p><p class="title"><a href="/2020/12/18/ncnn-lesson-8/">&lt; NCNN-Lession-8 &gt;　读取网络的权重信息</a></p><p class="categories"><a href="/categories/Deeplearning/">Deeplearning</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Billy&#039;s Blog</a><p class="is-size-7"><span>&copy; 2021 Billy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>