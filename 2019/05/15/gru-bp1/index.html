<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>&lt; Deeplarning &gt; Understand Backpropagation of RNN/GRU and Implement It in Pure Python---1 - Billy&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Billy&#039;s Blog"><meta name="msapplication-TileImage" content="/img/1.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Billy&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Understanding GRUAs we know, RNN has the disadvantage of gradient vanishing(gradient exploding).GRU is invented in order to prevent gradient vanishing, so it could encode the information from very ear"><meta property="og:type" content="blog"><meta property="og:title" content="&lt; Deeplarning &gt; Understand Backpropagation of RNN/GRU and Implement It in Pure Python---1"><meta property="og:url" content="https://zhengtq.github.io/2019/05/15/gru-bp1/"><meta property="og:site_name" content="Billy&#039;s Blog"><meta property="og:description" content="Understanding GRUAs we know, RNN has the disadvantage of gradient vanishing(gradient exploding).GRU is invented in order to prevent gradient vanishing, so it could encode the information from very ear"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhengtq.github.io/img/og_image.png"><meta property="article:published_time" content="2019-05-15T08:08:56.000Z"><meta property="article:modified_time" content="2020-11-17T11:29:13.538Z"><meta property="article:author" content="Billy"><meta property="article:tag" content="Deeplearning"><meta property="article:tag" content="Tensorflow"><meta property="article:tag" content="RNN"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zhengtq.github.io/2019/05/15/gru-bp1/"},"headline":"< Deeplarning > Understand Backpropagation of RNN/GRU and Implement It in Pure Python---1","image":["https://zhengtq.github.io/img/og_image.png"],"datePublished":"2019-05-15T08:08:56.000Z","dateModified":"2020-11-17T11:29:13.538Z","author":{"@type":"Person","name":"Billy"},"description":"Understanding GRUAs we know, RNN has the disadvantage of gradient vanishing(gradient exploding).GRU is invented in order to prevent gradient vanishing, so it could encode the information from very ear"}</script><link rel="canonical" href="https://zhengtq.github.io/2019/05/15/gru-bp1/"><link rel="icon" href="/img/1.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Billy&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Zhengtq"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-05-15T08:08:56.000Z" title="5/15/2019, 4:08:56 PM">2019-05-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-17T11:29:13.538Z" title="11/17/2020, 7:29:13 PM">2020-11-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span><span class="level-item">5 分钟 read (About 717 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">&lt; Deeplarning &gt; Understand Backpropagation of RNN/GRU and Implement It in Pure Python---1</h1><div class="content"><h1 id="Understanding-GRU"><a href="#Understanding-GRU" class="headerlink" title="Understanding GRU"></a>Understanding GRU</h1><p>As we know, RNN has the disadvantage of gradient vanishing(gradient exploding).GRU is invented in order to prevent gradient vanishing, <strong>so it could encode the information from very early time. Similarly to residual structure in CNN, GRU(or LSTM) could be seen RNN with residual block. That is to say that former hidden state is identically added to the newly computed hidden state(with a gate)</strong>.<br>For more details about GRU structure, you could check my former <a href="https://zhengtq.github.io/2019/01/05/tf-rnn-gru/">blog</a>.<br><span id="more"></span></p>
<p>#Forward Propagation of GRU<br>In this section, I will implement my pure python version of GRU forward propagation same to the implementation in TensorFlow.Talk is cheap, show you the code:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, prev_s, W,Wb,C,Cb, V, Vb</span>):</span></span><br><span class="line">    self.x_prev_s = np.concatenate((x, prev_s), axis = <span class="number">0</span>)</span><br><span class="line">    self.hidden_mum = <span class="built_in">len</span>(prev_s)</span><br><span class="line">    self.mulw = mulGate.forward(W, Wb,self.x_prev_s)</span><br><span class="line">    self.mulwsig = sig_act.forward(self.mulw) </span><br><span class="line"></span><br><span class="line">    self.r = self.mulwsig[:<span class="built_in">len</span>(self.mulwsig)/<span class="number">2</span>]</span><br><span class="line">    self.u = self.mulwsig[<span class="built_in">len</span>(self.mulwsig)/<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line">    self.r_state = eltwise_mul.forward(self.r, prev_s)</span><br><span class="line">    self.x_r_state = np.concatenate((x, self.r_state), axis = <span class="number">0</span>)</span><br><span class="line">    self.x_r_state_mulc =mulGate.forward(C,Cb, self.x_r_state)</span><br><span class="line">    self.x_r_state_mulc_tan = tan_act.forward(self.x_r_state_mulc)</span><br><span class="line"></span><br><span class="line">    self.tmpadd1 = eltwise_mul.forward(self.u, prev_s)</span><br><span class="line">    self.u_fu = <span class="number">1</span> - self.u</span><br><span class="line">    self.tmpadd2 = eltwise_mul.forward(self.u_fu, self.x_r_state_mulc_tan)</span><br><span class="line">    self.s = addGate.forward(self.tmpadd1, self.tmpadd2)</span><br><span class="line">    self.mulv = mulGate.forward(V,Vb, self.s)</span><br></pre></td></tr></table></figure></p>
<p>As you can see, we firstly concat ‘hpre’ and ‘x’ together, and then multiply with our first weigth ‘W’(Same to ‘hpre’ and ‘x’ seperatly multiply its weight and add together). <strong>Variable’r’ and ‘u’ are two gates. Gate ‘r’ controls how much hidden state infromation could be mixed with ‘x’. Gate ‘u’ controls how much hidden state information could be directly and identically flow to the next state</strong>.</p>
<p>#Back Propagation of GRU<br> As we know, RNN use <strong>back propagation through time(PBTT)</strong> to compute gradients for each weights. PBTT means the gradients should flow through time(reversely) which also means you should comput the gradient of hidden state at each time step and then feed back to the RNN block to furture compute gradients of the inner variables. The bellow code snippet is the gradient flow inner the GRU structure at one time step:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">self, x, prev_s, W, Wb, C, Cb, V, Vb,diff_s, dmulv</span>):</span></span><br><span class="line"></span><br><span class="line">    dV,dVb, dsv = mulGate.backward(V,Vb, self.s, dmulv)</span><br><span class="line">    ds = dsv + diff_s</span><br><span class="line">    dtmpadd1, dtmpadd2 = addGate.backward(self.tmpadd1, self.tmpadd2, ds)</span><br><span class="line">    du_fu, dx_r_state_mulc_tan = eltwise_mul.backward(self.u_fu, self.x_r_state_mulc_tan, dtmpadd2)</span><br><span class="line">    du1 = -du_fu</span><br><span class="line">    </span><br><span class="line">    du2, dprev_s0 = eltwise_mul.backward(self.u, prev_s, dtmpadd1)</span><br><span class="line">    du = du1 + du2</span><br><span class="line">    dx_r_state_mulc = tan_act.backward(self.x_r_state_mulc, dx_r_state_mulc_tan)</span><br><span class="line">    dC,dCb, dx_x_r_state = mulGate.backward(C,Cb, self.x_r_state, dx_r_state_mulc)</span><br><span class="line">    dx = dx_x_r_state[:<span class="built_in">len</span>(x)]</span><br><span class="line">    dr_state = dx_x_r_state[<span class="built_in">len</span>(x):]</span><br><span class="line">   </span><br><span class="line">    dr, dprev_s1 = eltwise_mul.backward(self.r, prev_s, dr_state)</span><br><span class="line">    dmulwsig = np.concatenate((dr, du), axis = <span class="number">0</span>)</span><br><span class="line">    dmulw = sig_act.backward(self.mulw, dmulwsig)</span><br><span class="line">    dW,dWb, dx_prev_s = mulGate.backward(W, Wb, self.x_prev_s, dmulw)</span><br><span class="line">    dprev_s = dx_prev_s[-self.hidden_mum:] + dprev_s1 + dprev_s0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (dprev_s, dW,dWb, dC,dCb, dV,dVb)</span><br></pre></td></tr></table></figure>
<p>Here I have admit that to write a back propagation algorithm is a fussy thing, for you should carefully compute the gradient flow through every operations without any error. There are some note for you. Firstly, while hidden state is used three times in the forward propagation(First branch: compute gate ‘r’ and gate ‘u’. Second branch: to mix information with input ‘x’. Third branch, identically add to the final hidden state), so you should add every gradient of hidden state computed from each branch<strong>(A way to prevent gradient vanishing)</strong>. Second thing to remember, feed your compute final gradient of hidden state to your last time step(or last layer of your model). </p>
</div><div class="article-licensing box"><div class="licensing-title"><p>&lt; Deeplarning &gt; Understand Backpropagation of RNN/GRU and Implement It in Pure Python---1</p><p><a href="https://zhengtq.github.io/2019/05/15/gru-bp1/">https://zhengtq.github.io/2019/05/15/gru-bp1/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Billy</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2019-05-15</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2020-11-17</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Deeplearning/">Deeplearning</a><a class="link-muted mr-2" rel="tag" href="/tags/Tensorflow/">Tensorflow</a><a class="link-muted mr-2" rel="tag" href="/tags/RNN/">RNN</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/05/27/DEMO/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">&lt; DEMO &gt; My work and DEMO</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/04/24/op-summary/"><span class="level-item">&lt;Deeplarning&gt; A simple way to distinguish different optimizers in DeepLearning</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>app_id</code> or <code>app_key</code> for Valine. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Billy&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Billy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Zhengtq"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>