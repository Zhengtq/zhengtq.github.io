<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-cn,en,default">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Tensorflow,">










<meta name="description" content="开始最近想尝试一下用Transformer做图片分类的效果，于是就在网上找找有没有比较好的例子．发现keras官方有个例子，于是就clone下来看看．本以为multi-head-attention这个模块需要自己来实现，竟然发现tf.keras中已经实现了multi-head-attention的接口，发现是真的方便（tensorflow的最新版本tf2.4才有的一个接口）． 跑了一个官方给的ci">
<meta name="keywords" content="Tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="&lt; Tensorflow &gt;Tensorflow2.4 最佳实践">
<meta property="og:url" content="http://yoursite.com/2021/01/27/tf2-x-best-practice/index.html">
<meta property="og:site_name" content="Billy&#39;s Blog">
<meta property="og:description" content="开始最近想尝试一下用Transformer做图片分类的效果，于是就在网上找找有没有比较好的例子．发现keras官方有个例子，于是就clone下来看看．本以为multi-head-attention这个模块需要自己来实现，竟然发现tf.keras中已经实现了multi-head-attention的接口，发现是真的方便（tensorflow的最新版本tf2.4才有的一个接口）． 跑了一个官方给的ci">
<meta property="og:locale" content="zh-cn">
<meta property="og:image" content="http://yoursite.com/2021/01/27/tf2-x-best-practice/before.png">
<meta property="og:image" content="http://yoursite.com/2021/01/27/tf2-x-best-practice/before1.png">
<meta property="og:updated_time" content="2021-01-27T07:59:32.508Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="&lt; Tensorflow &gt;Tensorflow2.4 最佳实践">
<meta name="twitter:description" content="开始最近想尝试一下用Transformer做图片分类的效果，于是就在网上找找有没有比较好的例子．发现keras官方有个例子，于是就clone下来看看．本以为multi-head-attention这个模块需要自己来实现，竟然发现tf.keras中已经实现了multi-head-attention的接口，发现是真的方便（tensorflow的最新版本tf2.4才有的一个接口）． 跑了一个官方给的ci">
<meta name="twitter:image" content="http://yoursite.com/2021/01/27/tf2-x-best-practice/before.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2021/01/27/tf2-x-best-practice/">





  <title>< Tensorflow >Tensorflow2.4 最佳实践 | Billy's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-cn">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Billy's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Make It Simple</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/27/tf2-x-best-practice/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Billy">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Billy's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">< Tensorflow >Tensorflow2.4 最佳实践</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-01-27T08:38:00+08:00">
                2021-01-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Tensorflow/" itemprop="url" rel="index">
                    <span itemprop="name">Tensorflow</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2021/01/27/tf2-x-best-practice/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2021/01/27/tf2-x-best-practice/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>p
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><p>最近想尝试一下用Transformer做图片分类的效果，于是就在网上找找有没有比较好的例子．发现keras官方有个例子，于是就clone下来看看．本以为multi-head-attention这个模块需要自己来实现，竟然发现tf.keras中已经实现了multi-head-attention的接口，发现是真的方便（tensorflow的最新版本tf2.4才有的一个接口）．</p>
<p>跑了一个官方给的cifar的例子，效果还行．于是就打算在自己的数据上跑跑看效果，在这个过程中，发现官方给你例子还远远达不到训练速度最优化的程度．于是就把官方例子就改了一下，最终达到了一个满意的训练速度，本篇就是记录一下tf2.4下的训练性能调优全过程．最终调优后的代码会共享出来．</p>
<h1 id="单卡到多卡"><a href="#单卡到多卡" class="headerlink" title="单卡到多卡"></a>单卡到多卡</h1><p>官方给的vit(Vision Transformer)的例子是基于单卡的，但是现在训练大型网络已经离不开多卡，于是把官方例子改成多卡训练的版本（这里主要说明一下单机多卡的设置）．</p>
<p><strong>首先根据你手上卡的数量来建立一个strategy的对象</strong>．</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">physical_devices = tf.config.list_physical_devices(<span class="string">'GPU'</span>)          </span><br><span class="line"><span class="keyword">for</span> ind, item <span class="keyword">in</span> enumerate(physical_devices):                      </span><br><span class="line">    tf.config.experimental.set_memory_growth(item, <span class="keyword">True</span>)           </span><br><span class="line">                                                                   </span><br><span class="line">TRAIN_GPUS = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]                                          </span><br><span class="line">devices = [<span class="string">"/gpu:&#123;&#125;"</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> TRAIN_GPUS]             </span><br><span class="line">strategy = tf.distribute.MirroredStrategy(devices)</span><br></pre></td></tr></table></figure>
<p>这里tf.config.experimental.set_memory_growth的作用是限制显存的使用．</p>
<p><strong>然后我们要把数据做一个副本化的包装：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)   </span><br><span class="line">test_dist_dataset = strategy.experimental_distribute_dataset(test_daset)</span><br></pre></td></tr></table></figure>
<p><strong>然后我们需要对train_step和test_step做一个封装：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> strategy.scope()</span><br><span class="line">       <span class="function"><span class="keyword">def</span> <span class="title">distributed_train_step</span><span class="params">(dataset_inputs)</span>:</span>                           </span><br><span class="line">           per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))                           </span><br><span class="line">           <span class="keyword">return</span> strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=<span class="keyword">None</span>)               </span><br><span class="line">       <span class="function"><span class="keyword">def</span> <span class="title">distributed_test_step</span><span class="params">(dataset_inputs)</span>:</span>                           </span><br><span class="line">           <span class="keyword">return</span> strategy.run(test_step, args=(dataset_inputs,))</span><br></pre></td></tr></table></figure>
<p><strong>最后在train_step，test_step，和计算loss和accuracy加上strategy的scope</strong>（这里只是拿train_step和test_step举例）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> strategy.scope():                                                       </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(inputs)</span>:</span>                                                  </span><br><span class="line">        images, labels = inputs                                              </span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:                                      </span><br><span class="line">            predictions = model(images, training=<span class="keyword">True</span>)                       </span><br><span class="line">            loss = compute_loss(labels, predictions)                         </span><br><span class="line">                                                                             </span><br><span class="line">        gradients = tape.gradient(loss, model.trainable_variables)           </span><br><span class="line">        optimizer.apply_gradients(zip(gradients, model.trainable_variables)) </span><br><span class="line">        compute_acc(labels, predictions, train_accuracy)                     </span><br><span class="line">        <span class="keyword">return</span> loss                                                          </span><br><span class="line">                                                                             </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_step</span><span class="params">(inputs)</span>:</span>                                                   </span><br><span class="line">        images, labels = inputs                                              </span><br><span class="line">        predictions = model(images, training=<span class="keyword">False</span>)                          </span><br><span class="line">        compute_acc(labels, predictions, test_accuracy)</span><br></pre></td></tr></table></figure>
<p>经过了上述的步骤，成功的在tf2.4下，把单卡训练转换到了单机多卡训练．</p>
<h1 id="eager-mode-到-static-graph-mode"><a href="#eager-mode-到-static-graph-mode" class="headerlink" title="eager mode 到 static graph mode"></a>eager mode 到 static graph mode</h1><p>由于tf2.x模式的执行方式是急切执行（eager mode），eager mode的好处在在于方便debug，但是如果拿来训练就不太好了，因为eager mode会托慢速度．所以我们需要在调试好网络之后把执行模式切换为静态图的模式．而这个步骤非常简单，<strong>加上一个tf.function的修饰符就好</strong>．</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> strategy.scope():                                                   </span><br><span class="line"><span class="meta">    @tf.function                                                         </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">distributed_train_step</span><span class="params">(dataset_inputs)</span>:</span>                           </span><br><span class="line">        per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))         </span><br><span class="line">        <span class="keyword">return</span> strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=<span class="keyword">None</span>)             </span><br><span class="line"><span class="meta">    @tf.function                                                         </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">distributed_test_step</span><span class="params">(dataset_inputs)</span>:</span>                           </span><br><span class="line">        <span class="keyword">return</span> strategy.run(test_step, args=(dataset_inputs,))</span><br></pre></td></tr></table></figure>
<h1 id="调整tf-data数据流顺序"><a href="#调整tf-data数据流顺序" class="headerlink" title="调整tf.data数据流顺序"></a>调整tf.data数据流顺序</h1><p>tf.data的数据处理顺序非常重要，改变顺序可能会极度的托慢训练速度．</p>
<p>这里，我的数据处理流程如下：</p>
<ol>
<li>读取所有图片的路径和对应的label．</li>
<li>把图片路径给parse成图片．</li>
</ol>
<p>流程其实很简单，但这里要涉及到几点：</p>
<ol>
<li>如何shuffle.</li>
<li>哪里设定epoch</li>
<li>哪里设定batch</li>
<li>哪里设定预取prefetch．</li>
</ol>
<p>先来上code，再解释：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">  image_roots, labels = generate_fileroots_labels(file_root)                   </span><br><span class="line">  dataset = tf.data.Dataset.from_tensor_slices((image_roots, labels))           </span><br><span class="line">  dataset = dataset.repeat(<span class="number">100</span>).shuffle(buffer_size=<span class="number">2000</span>) </span><br><span class="line"><span class="comment">#  dataset = dataset.map(_parse_data, num_parallel_calls=tf.data.experimental.AUTOTUNE) </span></span><br><span class="line">  dataset = dataset.map(_parse_data, num_parallel_calls=<span class="number">16</span>)                     </span><br><span class="line">  dataset = dataset.batch(batch_size)                                           </span><br><span class="line">  dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)</span><br></pre></td></tr></table></figure>
<p>首先，repeat表示需要把数据重复多少次，也就是设定的epoc，shuffle代表在多少的buffer中打乱数据．<strong>这两者需要放到map前面</strong>，因为在map前，数据流处理的都是图片路径和label的轻量化数据，这对于repeat和shuffle是有利的．</p>
<p>而batch和prefetch就需要放到map的后面．<strong>这里需要注意，要先设定batch，再prefetch（不然会慢）</strong>．</p>
<h1 id="大杀器－－tf-profiler"><a href="#大杀器－－tf-profiler" class="headerlink" title="大杀器－－tf.profiler"></a>大杀器－－tf.profiler</h1><p>当我们觉得已经把加速做到极致了之后，我们需要用tensorflow自带的性能检测工具tf.profiler来检查一些性能还有那些可以榨取的空间．</p>
<p>用tf.profiler之前，你需要先按照官方的教程<a href="https://github.com/tensorflow/profiler" target="_blank" rel="noopener">安装</a>．这里有个小坑，因为tf.profiler需要依赖libcupti这个库，而libcupti这个库不在cuda的主库目录里，而是在extras/CUPTI/lib64里面，这个需要注意．</p>
<p>然后在你的训练代码中，需要添加如下的code：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> t_step, x <span class="keyword">in</span> enumerate(train_dist_dataset):</span><br><span class="line">    <span class="keyword">if</span> t_step == <span class="number">500</span>:</span><br><span class="line">          tf.profiler.experimental.start(<span class="string">'/tmp/'</span> + datetime.datetime.now().strftime(<span class="string">"%Y%m%d-%H%M%S"</span>))</span><br><span class="line">    <span class="keyword">if</span> t_step == <span class="number">600</span>:</span><br><span class="line">          tf.profiler.experimental.stop()</span><br><span class="line">    <span class="keyword">with</span> tf.profiler.experimental.Trace(<span class="string">'Train'</span>, step_num=t_step, _r=<span class="number">1</span>):</span><br><span class="line">        step_loss = distributed_train_step(x)</span><br></pre></td></tr></table></figure>
<p>这个代码段的意思是，在训练的第200步到第300步需要记录你的训练profile．</p>
<p>这里说明两点：</p>
<p>第一，<strong>我们不需要要整个训练过程都记录profile</strong>，因为记录profile仅仅是为了调优，只需要记录某些步的profile就可以提供你来调优即可．</p>
<p>第二，<strong>不从第０步就开始记录是因为我们需要先让训练达到稳定之后记录才会比较准确</strong>（示例中是从500步到600步开始记录profile）．</p>
<p>好了，我们看一下，都记录了一些什么东西：</p>
<p><img src="/2021/01/27/tf2-x-best-practice/before.png" alt=""></p>
<p>这里我们可以看到耗时主要在3个方面：</p>
<ol>
<li><strong>Kernel Launch Time</strong>  </li>
<li><strong>Host Compute Time</strong></li>
<li><strong>Device Compute Time</strong></li>
</ol>
<p>我们来一个一个解决，首先来解决kernel lanuch time，这个在右边的建议(Recommendation for Next Step)有说明：</p>
<blockquote>
<ul>
<li>14.3 % of the total step time sampled is spent on ‘Kernel Launch’. It could be due to CPU contention with tf.data. In this case, you may try to set the environment variable TF_GPU_THREAD_MODE=gpu_private.</li>
</ul>
</blockquote>
<p>也就是说可以通过设定TF_GPU_THREAD_MODE=gpu_private来解决．也就是说要在之前训练程序的前面加上下面一句命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> TF_GPU_THREAD_MODE=gpu_private</span><br></pre></td></tr></table></figure>
<p>然而我这样执行之后发现作用好像不是很大，知道怎么解决的同学可以交流．</p>
<p>我们现在来解决第二个主要耗时的点，也就是Host Compute Time耗时过高．</p>
<p>我们知道，tensorflow的多卡策略是ps-worker的方式，这个ps可以认为是host，主要是负责更新参数和处理数据流，按理说这部分的耗时不应该很高才对．于是我往下看具体的host的耗时的页面：</p>
<p><img src="/2021/01/27/tf2-x-best-practice/before1.png" alt=""></p>
<p>我们看到，host的耗时，很大的程度和２个op有关：</p>
<ol>
<li>stridedSlide</li>
<li>cast</li>
</ol>
<p>其中stridedSlide占了绝对的大头，经过查阅资料发现，stridedSlide耗时比较高主要和tf.distribute.MirroredStrategy这个对象有关．</p>
<p>因为我在我的工程里面用到了tf.data.Dataset.from_tensor_slices这个对象，这个对象用到了stridedSlide这个操作，而tf.distribute.MirroredStrategy对stridedSlide的操作支持的不好．</p>
<p>网上的建议是把tf.distribute.MirroredStrategy换成tf.distribute.experimental.MultiWorkerMirroredStrategy．</p>
<p>也就是如下实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  TRAIN_GPUS = [0,1,2,3]</span></span><br><span class="line"><span class="comment">#  devices = ["/gpu:&#123;&#125;".format(i) for i in TRAIN_GPUS]</span></span><br><span class="line"><span class="comment">#  strategy = tf.distribute.MirroredStrategy(devices)</span></span><br><span class="line">tf.config.set_visible_devices(physical_devices[<span class="number">0</span>:<span class="number">8</span>], <span class="string">'GPU'</span>) </span><br><span class="line">strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()</span><br></pre></td></tr></table></figure>
<p>更换了之后，果然<strong>Host Compute Time</strong> 得到了下降．</p>
<p>关于cast这个操作，是因为我在dataset的parse_function里面用到了tf.cast的操作，我把这个操作放到了网络里面，这部分的耗时也消除了（其实是分给worker了）．</p>
<p>关于<strong>Device Compute Time</strong>这一部分，我发现这个部分主要的耗时用到了矩阵操作Einsum上，这一部分的操作也是MultiHeadAttention的主要操作，于是也就没有修改这个部分．</p>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>当然，说了这么多，不如大家来下面一行代码来的方便…..</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import torch as tf</span><br></pre></td></tr></table></figure>
<p>不过话说回来，tensorflow和pytorch不是二选一的问题，而是大家最好都会用，这样才能更好在深度学习里探(lian)索(dan)．</p>
<p>最后把示例代码放到<a href="https://github.com/Zhengtq/tensorflow2.x-best-practice" target="_blank" rel="noopener">这里</a>，大家自行取用．</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Tensorflow/" rel="tag"># Tensorflow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/12/28/ncnn-lesson-start/" rel="next" title="< NCNN-Lession-Start >　Start">
                <i class="fa fa-chevron-left"></i> < NCNN-Lession-Start >　Start
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/head.png" alt="Billy">
            
              <p class="site-author-name" itemprop="name">Billy</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">45</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Zhengtq" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:ztqstd@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://zhengtq.github.io/2019/05/27/DEMO/" target="_blank" title="DEMO">
                      
                        <i class="fa fa-fw fa-angle-right"></i>DEMO</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Friends
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.cnblogs.com/zjutzz" title="ChrisZZ" target="_blank">ChrisZZ</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#开始"><span class="nav-number">1.</span> <span class="nav-text">开始</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#单卡到多卡"><span class="nav-number">2.</span> <span class="nav-text">单卡到多卡</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#eager-mode-到-static-graph-mode"><span class="nav-number">3.</span> <span class="nav-text">eager mode 到 static graph mode</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#调整tf-data数据流顺序"><span class="nav-number">4.</span> <span class="nav-text">调整tf.data数据流顺序</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#大杀器－－tf-profiler"><span class="nav-number">5.</span> <span class="nav-text">大杀器－－tf.profiler</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#最后"><span class="nav-number">6.</span> <span class="nav-text">最后</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Billy</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      p
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      p
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'BGzxkVpRtr5PoQUppRDqiC1V-gzGzoHsz',
        appKey: 'K9tU9mVpjknHh8SNOWrqXqDV',
        placeholder: 'Just go go',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  





  

  

  

  
  

  

  

  

</body>
</html>
