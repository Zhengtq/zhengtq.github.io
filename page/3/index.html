<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>Billy&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Billy&#039;s Blog"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Billy&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="website"><meta property="og:title" content="Billy&#039;s Blog"><meta property="og:url" content="https://zhengtq.github.io/"><meta property="og:site_name" content="Billy&#039;s Blog"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhengtq.github.io/img/og_image.png"><meta property="article:author" content="Billy"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zhengtq.github.io"},"headline":"Billy's Blog","image":["https://zhengtq.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Billy"},"description":null}</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">Billy&#039;s Blog</a></div><div class="navbar-menu"><div class="navbar-end"></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-04-24T08:58:01.000Z" title="4/24/2019, 4:58:01 PM">2019-04-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-12T07:43:34.835Z" title="3/12/2021, 3:43:34 PM">2021-03-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/04/24/op-summary/">&lt;Deeplarning&gt; A simple way to distinguish different optimizers in DeepLearning</a></h1><div class="content"><h1 id="The-optimizers"><a href="#The-optimizers" class="headerlink" title="The optimizers"></a>The optimizers</h1><p>Let’s simply list the optimizers that may or may not be used in your project.</p>
<ul>
<li>SGDOptimizer</li>
<li>MomentumOptimizer</li>
<li>NesterovOptimizer</li>
<li>AdagradOptimizer</li>
<li>AdadeltaOptimizer</li>
<li>RMSPropOptimizer</li>
<li>AdamOptimizer</li>
<li>NadamOptimizer</li></ul></div><a class="article-more button is-small is-size-7" href="/2019/04/24/op-summary/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-04-19T08:04:59.000Z" title="4/19/2019, 4:04:59 PM">2019-04-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-12T08:02:05.872Z" title="3/12/2021, 4:02:05 PM">2021-03-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/04/19/motion-blink-rnn/">&lt; Deeplearning &gt; Use CNN and RNN to detect blink in a video</a></h1><div class="content"><h1 id="Let’s-do-it"><a href="#Let’s-do-it" class="headerlink" title="Let’s do it!"></a>Let’s do it!</h1><p>If you use your face to pay a sum of money by ALIPAY, you may find that it requires you to do some facial movement to check whether you are a real person or not. </p>
<p>So as you see, facial motion detection is  actually being used in many circumstances. You may want to figure out how to detect facial motion. </p>
<p>In this post, I will take motion blink as a example to demonstrate how to do realize it. </p>
<p>So Let’s do it.<br></p></div><a class="article-more button is-small is-size-7" href="/2019/04/19/motion-blink-rnn/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-04-19T05:26:26.000Z" title="4/19/2019, 1:26:26 PM">2019-04-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-17T11:29:17.206Z" title="11/17/2020, 7:29:17 PM">2020-11-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Linux/">Linux</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/04/19/linux-install-config/">&lt; Linux &gt; As a AI-practitioner, what I install in my linux system</a></h1><div class="content"><p>These are the tools(part) that I installed in my linux workspace. Hopefully it could help improve your efficiency.<br></p></div><a class="article-more button is-small is-size-7" href="/2019/04/19/linux-install-config/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-29T03:14:45.000Z" title="3/29/2019, 11:14:45 AM">2019-03-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-12T07:53:41.800Z" title="3/12/2021, 3:53:41 PM">2021-03-12</time></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/29/network-depthwise/">&lt; Network &gt; Understanding DepthWiseConv</a></h1><div class="content"><h1 id="Some-knowledge-about-DepthWiseConv"><a href="#Some-knowledge-about-DepthWiseConv" class="headerlink" title="Some knowledge about DepthWiseConv"></a>Some knowledge about DepthWiseConv</h1><p>As we all know, people invent DepthWiseConv for more efficient computation cost without accuracy loss. </p>
<p>DepthwiseConv coupled with PointWiseConv could be equal to normal convlution. </p>
<p>DepthWiseConv means that we assign a single kernel to each feature channel. PointWiseConv is a normal convolution kernel with kernel size 1 and stride 1. </p>
<p>DepthWiseConv aims to extract the spatial feature of a feature map, while PointWiseConv aims to extracte the correlation of different feature maps.<br></p></div><a class="article-more button is-small is-size-7" href="/2019/03/29/network-depthwise/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-25T09:22:38.000Z" title="3/25/2019, 5:22:38 PM">2019-03-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-12T06:44:17.371Z" title="3/12/2021, 2:44:17 PM">2021-03-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/25/tf-quant/">&lt; Tensorflow &gt;How dose TensorFlow do Quant Aware Training?</a></h1><div class="content"><h1 id="Let-firstly-simplify-the-Quant-process-in-TF"><a href="#Let-firstly-simplify-the-Quant-process-in-TF" class="headerlink" title="Let firstly simplify the Quant process in TF"></a>Let firstly simplify the Quant process in TF</h1><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">S_a1(q_a1 + Z_a1) &#x3D; S_w1(q_w1 + Z_w1) * S_a0(q_a0 + Z_a0)</span><br></pre></td></tr></table></figure>
<ul>
<li>q_a1: Quanted activation value in layer 1</li>
<li><p>S_a1, Z_a1:  <strong>Estimated</strong> scale and zero point in layer 1</p>
</li>
<li><p>q_w1: Quanted weight in layer 1</p>
</li>
<li><p>S_w1, Z_w1:  <strong>Statistical</strong> scale and zero point in layer 1</p>
</li>
<li><p>q_a0: Quanted activation value in layer 0</p>
</li>
<li>S_a0, Z_a0:  <strong>Estimated</strong> scale and zero point in layer 0</li>
</ul>
<p>As we can see, in order to compute q_a1(Quanted activation value in layer 1), we have to get S_w1, Z_w1, S_a0, Z_a0, q_a1, Z_a1. To get S_w1/Z_w1 is simple, we can get the Statistical maximum of the weights in each layer we want. The only tricky thing is how to get S_a1/Z_a1/S_a0/Z_a0, which have to be estimated from the training data.<br></p></div><a class="article-more button is-small is-size-7" href="/2019/03/25/tf-quant/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-16T03:39:28.000Z" title="3/16/2019, 11:39:28 AM">2019-03-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-17T11:29:41.647Z" title="11/17/2020, 7:29:41 PM">2020-11-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/16/antispoof-multi-task-learn/">&lt; Antispoofing &gt; Multi-Task-Learning in Face Antispoofing</a></h1><div class="content"><h1 id="Is-Face-Antispoofing-only-a-binary-classification-task"><a href="#Is-Face-Antispoofing-only-a-binary-classification-task" class="headerlink" title="Is Face Antispoofing only a binary classification task?"></a>Is Face Antispoofing only a binary classification task?</h1><p>Of course, we can consider face antispoofing task a binary classification task. We can train a classifier to seperate a human face image from liveness to fake. It may work well but it can not fully use all information in an face image. In order to push the limite of our trained data and our trained classifier, we have to cultivate other information that could help us to better discriminate a attack image.<br></p></div><a class="article-more button is-small is-size-7" href="/2019/03/16/antispoof-multi-task-learn/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-03-06T07:35:55.000Z" title="3/6/2019, 3:35:55 PM">2019-03-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-17T11:29:20.794Z" title="11/17/2020, 7:29:20 PM">2020-11-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/03/06/dataset-cut/">&lt; DeepLearning &gt; The Support Vectors in DeepLearning</a></h1><div class="content"><h1 id="Dose-DeepLearning-has-‘Support-Vectors’"><a href="#Dose-DeepLearning-has-‘Support-Vectors’" class="headerlink" title="Dose DeepLearning has ‘Support Vectors’?"></a>Dose DeepLearning has ‘Support Vectors’?</h1><p>As we all know, support vectors is a notation in SVM(Support Vector Machine). Support vectors means that the data points in the decision boundary(the Maximum Margin in SVM) are very important in a classification algorithm.  We can train a SVM only with the ‘Support Vectors’ that can achieve the same accuracy with models trained with more data.  So does the ‘Support Vectors’ exists in DeepLearning?<br></p></div><a class="article-more button is-small is-size-7" href="/2019/03/06/dataset-cut/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-02-01T02:12:19.000Z" title="2/1/2019, 10:12:19 AM">2019-02-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-17T11:29:13.958Z" title="11/17/2020, 7:29:13 PM">2020-11-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/02/01/face-as-1/">&lt; Antispoofing &gt; Data Augmentation in Face Antispoofing</a></h1><div class="content"><h1 id="How-dose-people-spoof-a-digital-device-with-face-recognition"><a href="#How-dose-people-spoof-a-digital-device-with-face-recognition" class="headerlink" title="How dose people spoof a digital device with face recognition"></a>How dose people spoof a digital device with face recognition</h1><p>To attack a image recognition system is easy. Even to change a single pixel could successfully let the recogniztion system lose efficacy.So people would use the loophole to simulate a set of conditions to spoof the face recogniztion system. In order to defense the spoofing, we should simulate all the possible attacking condition in the real life with limited training dataset.<br></p></div><a class="article-more button is-small is-size-7" href="/2019/02/01/face-as-1/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-01-30T01:19:16.000Z" title="1/30/2019, 9:19:16 AM">2019-01-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-17T11:29:16.478Z" title="11/17/2020, 7:29:16 PM">2020-11-17</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/01/30/face-as/">&lt; Antispoofing &gt; Does we should align in Face Antispoofing</a></h1><div class="content"><h1 id="Align-or-not-Texture-or-shape"><a href="#Align-or-not-Texture-or-shape" class="headerlink" title="Align or not, Texture or shape"></a>Align or not, Texture or shape</h1><h2 id="Relationship-with-Face-Recognition-FR"><a href="#Relationship-with-Face-Recognition-FR" class="headerlink" title="Relationship with Face Recognition(FR)"></a>Relationship with Face Recognition(FR)</h2><p>The aim of Face Recognition is to shorten the distance of one person from different scene, even from different medium. For example, FR should shorten the distance between the person in real life and the person’s picture in paper or tv or phone.<br>However, Face Antispoofing(FA) just did the opposite thing. FA should shorten the person from the same medium. For example, FA should shroten the distance between the two different person from the same medium. And FA should widen the distance the people from different medium, even the two persons are the same.<br>So as we can see, to differentiate medium is the key in FA.<br></p></div><a class="article-more button is-small is-size-7" href="/2019/01/30/face-as/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-01-09T11:04:09.000Z" title="1/9/2019, 7:04:09 PM">2019-01-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-12T06:16:24.603Z" title="3/12/2021, 2:16:24 PM">2021-03-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Deeplearning/">Deeplearning</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/01/09/tf-read-data/">&lt; Tensorflow &gt; Data flow in Tensorflow</a></h1><div class="content"><h1 id="Using-data-queue-to-read-data-abandoned-not-support-in-future-Tensorflow-version"><a href="#Using-data-queue-to-read-data-abandoned-not-support-in-future-Tensorflow-version" class="headerlink" title="Using data queue to read data(abandoned, not support in future Tensorflow version)"></a>Using data queue to read data(abandoned, not support in future Tensorflow version)</h1><p>If you store you data in traditional hard disk, I suggest you read data through the data format of  tfrecord. However, if you store your data in solid state drives , I suggest that you read by FIFO Queue to directly read image by its root.<br>Firstly, you have to set up a FIFO Queue:<br></p></div><a class="article-more button is-small is-size-7" href="/2019/01/09/tf-read-data/#more">Read more</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/2/">Previous</a></div><div class="pagination-next"><a href="/page/4/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link is-current" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><a class="pagination-link" href="/page/5/">5</a></li></ul></nav></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">Billy&#039;s Blog</a><p class="is-size-7"><span>&copy; 2021 Billy</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><!--!--><script src="/js/main.js" defer></script><!--!--></body></html>